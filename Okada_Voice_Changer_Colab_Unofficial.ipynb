{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stevens0856/OkadaVoiceChanger/blob/main/Okada_Voice_Changer_Colab_Unofficial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnR6lSmXBCN"
      },
      "source": [
        "<h1 style=\"text-align: center;\">\n",
        "  <span style=\"color: #00ffff;\">OKADA VOICE CHANGER COLAB (UNOFFICIAL)</span>\n",
        "</h1>\n",
        "\n",
        "\n",
        "For mobile user may experience bugs and feature limitations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FhcKp_4FXFRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0e5fd9-7093-4a99-c60f-cfaa91fc90dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m\u001b[1m\u001b[3mCell 1 Was Executed Completely\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#=================Updated=================\n",
        "# @title **Cell[1]** Clone repository and install dependencies\n",
        "# @markdown This first step will download the latest version of Voice Changer and install the dependencies. **It can take some time to complete.**\n",
        "import os\n",
        "import time\n",
        "import subprocess\n",
        "import threading\n",
        "import shutil\n",
        "import base64\n",
        "import codecs\n",
        "import torch\n",
        "import sys\n",
        "import requests\n",
        "from IPython.display import clear_output\n",
        "from typing import Literal, TypeAlias\n",
        "from google.colab import drive\n",
        "\n",
        "# Fix some packages\n",
        "!pip install pip==24.0.0 -q\n",
        "\n",
        "Mode: TypeAlias = Literal[\"elf\", \"zip\"]\n",
        "mode:Mode=\"elf\"\n",
        "\n",
        "# Configs\n",
        "%cd /content\n",
        "Run_Cell=0\n",
        "\n",
        "#@markdown Pilih Versi Okada Voice Changer / Choose Okada Voice Changer Version\n",
        "version = \"V1(new)\" #@param [\"V1(old)\", \"V1(new)\", \"V2\"]\n",
        "\n",
        "current_version_hash=None\n",
        "latest_version_hash=None\n",
        "\n",
        "# Check GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available\")\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"GPU is not available\")\n",
        "    # sys.exit(\"No GPU available. Change runtime.\")\n",
        "\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "if version == \"V1(new)\":\n",
        "    print('\\033[36m\\033[1m\\033[3mDownloading prebuilt executable...\\033[0m')\n",
        "    res = requests.get('https://api.github.com/repos/deiteris/voice-changer/releases/latest')\n",
        "    release_info = res.json()\n",
        "\n",
        "    for asset in release_info['assets']:\n",
        "        if not asset['name'].startswith('voice-changer-linux-amd64-cuda.tar.gz'):\n",
        "            continue\n",
        "        download_url = asset['browser_download_url']\n",
        "        !wget -q --show-progress {download_url}\n",
        "\n",
        "    print('\\033[32m\\033[1m\\033[3mUnpacking...\\033[0m')\n",
        "    !cat voice-changer-linux-amd64-cuda.tar.gz.* | tar xzf -\n",
        "    !rm -rf voice-changer-linux-amd64-cuda.tar.gz.*\n",
        "    print('\\033[32m\\033[1m\\033[3mFinished unpacking!\\033[0m')\n",
        "\n",
        "    path = codecs.decode('ZZIPFreireFVB', 'rot_13')\n",
        "\n",
        "    %cd $path\n",
        "\n",
        "    # Additional\n",
        "    !pip install python-dotenv pyngrok --quiet\n",
        "\n",
        "    print('\\033[32m\\033[1m\\033[3mSuccessfully downloaded and unpacked the binary!!\\033[0m')\n",
        "    # libportaudio2\n",
        "    print('\\033[36m\\033[1m\\033[3mInstalling libportaudio2...\\033[0m')\n",
        "    !apt-get -y install libportaudio2 -qq\n",
        "\n",
        "    # Server Config\n",
        "    %cd /content/$path\n",
        "\n",
        "    from dotenv import set_key\n",
        "\n",
        "    set_key('.env', \"SAMPLE_MODE\", \"\")\n",
        "\n",
        "    Ready = True\n",
        "\n",
        "    clear_output()\n",
        "    print('\\033[32m\\033[1m\\033[3mCell 1 Was Executed Completely\\033[0m')\n",
        "\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "elif version == \"V1(old)\":\n",
        "\n",
        "    from IPython.display import clear_output\n",
        "\n",
        "    # Define the URL and the destination paths\n",
        "    url = 'https://huggingface.co/freyza/w-okada/resolve/main/w-okada.zip'\n",
        "    zip_path = '/content/w-okada.zip'\n",
        "    extract_path = '/content'\n",
        "\n",
        "    # Download the zip file\n",
        "    subprocess.run(['wget', '-q', '-O', zip_path, url], check=True)\n",
        "\n",
        "    # Unzip the downloaded file to the specified directory\n",
        "    subprocess.run(['unzip', '-o', '-q', zip_path, '-d', extract_path], check=True)\n",
        "\n",
        "    # Remove the zip file after extraction\n",
        "    subprocess.run(['rm', zip_path], check=True)\n",
        "\n",
        "    # List the contents to verify\n",
        "    subprocess.run(['ls', extract_path], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "    # Install libportaudio2\n",
        "    %cd /content/w-okada/server\n",
        "    print('\\033[36m\\033[1m\\033[3mInstalling libportaudio2...\\033[0m')\n",
        "    !apt-get -y install libportaudio2 -qq\n",
        "\n",
        "    # Install additional dependencies\n",
        "    print('\\033[36m\\033[1m\\033[3mInstalling pre-dependencies...\\033[0m')\n",
        "    !python -m pip install ort-nightly-gpu --index-url=https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ort-cuda-12-nightly/pypi/simple/ -q\n",
        "    !pip install faiss-gpu fairseq pyngrok --quiet\n",
        "    !pip install pyworld --no-build-isolation --quiet\n",
        "\n",
        "    # Install dependencies from requirements.txt\n",
        "    print('\\033[36m\\033[1m\\033[3mInstalling dependencies from requirements.txt...\\033[0m')\n",
        "    !pip install -r requirements.txt --quiet\n",
        "\n",
        "    clear_output()\n",
        "    print('\\033[32m\\033[1m\\033[3mCell 1 Was Executed Completely\\033[0m')\n",
        "\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "elif version == \"V2\":\n",
        "\n",
        "    from IPython.display import clear_output, Javascript\n",
        "\n",
        "    work_dir = \"/content\"\n",
        "    print(\"Downloading the latest vcclient... \")\n",
        "    !curl -s -L https://huggingface.co/wok000/vcclient000_colab/resolve/main/latest_hash.txt -o latest_hash.txt\n",
        "    latest_version_hash = open('latest_hash.txt').read().strip()\n",
        "\n",
        "    if mode == \"elf\":\n",
        "        !curl -L https://huggingface.co/wok000/vcclient000_colab/resolve/main/vcclient_latest_for_colab -o {work_dir}/vcclient_latest_for_colab\n",
        "    elif mode == \"zip\":\n",
        "        !curl -L https://huggingface.co/wok000/vcclient000_colab/resolve/main/vcclient_latest_for_colab -o {work_dir}/vcclient_latest_for_colab.zip\n",
        "\n",
        "    print(\"Download is done.\")\n",
        "\n",
        "    if current_version_hash != latest_version_hash and mode == \"zip\":\n",
        "        print(f\"Unzip vcclient to {latest_version_hash} ... \")\n",
        "        !cd {work_dir} && unzip -q vcclient_latest_for_colab.zip -d {latest_version_hash}\n",
        "        print(f\"Unzip is done.\")\n",
        "\n",
        "    if mode == \"elf\":\n",
        "        %cd {work_dir}\n",
        "        !chmod 0700 vcclient_latest_for_colab\n",
        "    elif mode == \"zip\":\n",
        "        %cd {work_dir}/{latest_version_hash}/main\n",
        "        !chmod 0700 main\n",
        "\n",
        "    print(\"Installing modules... \", end=\"\")\n",
        "    !sudo apt-get install -y libportaudio2 > /dev/null 2>&1\n",
        "    !pip install pyngrok > /dev/null 2>&1\n",
        "    clear_output()\n",
        "    print('\\033[32m\\033[1m\\033[3mV2 Cell 1 Was Executed Completely\\033[0m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8-mkn17pT2W",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43423e1e-e85f-427d-d241-3b24c27d25c4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------- SERVER READY! ---------\n",
            "Your server is available at:\n",
            "https://2bd9-34-16-138-214.ngrok-free.app\n",
            "---------------------------------\n",
            "2024-12-13 00:53:31,247 INFO     [main] --------\n",
            "2024-12-13 00:53:31,248 INFO     [main] The server is listening on http://127.0.0.1:18888/\n",
            "2024-12-13 00:53:31,248 INFO     [main] --------\n",
            "2024-12-13 00:54:16,273 INFO     [MMVC_Namespace] Connected SID: kzEmF9lyYCf9wok6AAAB\n",
            "2024-12-13 00:56:04,740 INFO     [MMVC_Rest_Fileuploader] paramDict\n",
            "2024-12-13 00:56:04,740 INFO     [VoiceChangerManager] FILE: LoadModelParamFile(name='zetaTest.pth', kind='rvcModel', dir='')\n",
            "2024-12-13 00:56:04,740 INFO     [VoiceChangerManager] Moving /tmp/tmpes66vydm/upload_dir/zetaTest.pth -> model_dir/0/zetaTest.pth\n",
            "2024-12-13 00:56:04,740 INFO     [RVCModelSlotGenerator] RVC:: slotInfo.modelFile zetaTest.pth\n",
            "voice_changer/RVC/RVCModelSlotGenerator.py:57: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cpt = torch.load(modelPath, map_location=\"cpu\")\n",
            "2024-12-13 00:56:04,822 INFO     [RVCModelSlotGenerator] Official Model(pyTorch) : v2\n",
            "voice_changer/common/SafetensorsUtils.py:52: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data: dict = torch.load(pt_filename, map_location=\"cpu\")\n",
            "2024-12-13 00:56:05,253 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=-1, voiceChangerType='RVC', name='zetaTest', description='', credit='', termsOfUseUrl='', iconFile='', speakers={0: 'target'}, modelFile='zetaTest.safetensors', modelFileOnnx='', indexFile='', defaultTune=0, defaultFormantShift=0, defaultIndexRatio=0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=40000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 00:56:05,260 INFO     [VoiceChangerManager] params, LoadModelParams(voiceChangerType='RVC', slot=0, isSampleMode=False, sampleId=None, files=[LoadModelParamFile(name='zetaTest.pth', kind='rvcModel', dir='')], params={})\n",
            "2024-12-13 00:56:19,222 INFO     [VoiceChangerManager] update configuration modelSlotIndex: 0\n",
            "2024-12-13 00:56:19,223 INFO     [VoiceChangerManager] Model slot is changed -1 -> 0\n",
            "2024-12-13 00:56:19,223 INFO     [VoiceChangerManager] Loading RVC...\n",
            "2024-12-13 00:56:19,223 INFO     [RVCr2] Allocated audio buffer size: 9792\n",
            "2024-12-13 00:56:19,223 INFO     [RVCr2] Allocated convert buffer size: 18080\n",
            "2024-12-13 00:56:19,223 INFO     [RVCr2] Allocated pitchf buffer size: 114\n",
            "2024-12-13 00:56:19,223 INFO     [RVCr2] Initializing...\n",
            "torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n",
            "2024-12-13 00:56:19,936 INFO     [RVCInferencerv2] Compiling JIT model...\n",
            "2024-12-13 00:56:21,959 INFO     [EmbedderManager] Loading embedder hubert_base\n",
            "2024-12-13 00:56:21,960 INFO     [OnnxLoader] Quantizing model...\n",
            "2024-12-13 00:56:21,960 INFO     [shape_inference] Performing symbolic shape inference...\n",
            "2024-12-13 00:56:46,173 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/feature_projection/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:46,247 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:46,412 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.0/attention/MatMul]\n",
            "2024-12-13 00:56:46,498 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.0/attention/MatMul_1]\n",
            "2024-12-13 00:56:46,499 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.0/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:46,598 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.0/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:46,934 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.0/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:47,061 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.0/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:47,216 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.1/attention/MatMul]\n",
            "2024-12-13 00:56:47,293 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.1/attention/MatMul_1]\n",
            "2024-12-13 00:56:47,294 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.1/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:47,368 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.1/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:47,723 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.1/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:47,843 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.1/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:48,006 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.2/attention/MatMul]\n",
            "2024-12-13 00:56:48,087 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.2/attention/MatMul_1]\n",
            "2024-12-13 00:56:48,088 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.2/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:48,163 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.2/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:48,496 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.2/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:48,633 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.2/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:48,790 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.3/attention/MatMul]\n",
            "2024-12-13 00:56:48,869 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.3/attention/MatMul_1]\n",
            "2024-12-13 00:56:48,870 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.3/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:48,951 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.3/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:49,283 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.3/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:49,401 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.3/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:49,553 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.4/attention/MatMul]\n",
            "2024-12-13 00:56:49,652 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.4/attention/MatMul_1]\n",
            "2024-12-13 00:56:49,654 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.4/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:49,739 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.4/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:50,066 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.4/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:50,183 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.4/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:50,343 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.5/attention/MatMul]\n",
            "2024-12-13 00:56:50,422 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.5/attention/MatMul_1]\n",
            "2024-12-13 00:56:50,423 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.5/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:50,502 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.5/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:50,858 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.5/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:50,979 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.5/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:51,147 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.6/attention/MatMul]\n",
            "2024-12-13 00:56:51,224 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.6/attention/MatMul_1]\n",
            "2024-12-13 00:56:51,225 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.6/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:51,303 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.6/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:51,639 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.6/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:51,773 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.6/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:51,941 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.7/attention/MatMul]\n",
            "2024-12-13 00:56:52,021 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.7/attention/MatMul_1]\n",
            "2024-12-13 00:56:52,022 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.7/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:52,114 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.7/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:52,447 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.7/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:52,567 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.7/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:52,741 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.8/attention/MatMul]\n",
            "2024-12-13 00:56:52,818 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.8/attention/MatMul_1]\n",
            "2024-12-13 00:56:52,819 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.8/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:52,897 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.8/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:53,227 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.8/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:53,341 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.8/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:53,496 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.9/attention/MatMul]\n",
            "2024-12-13 00:56:53,579 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.9/attention/MatMul_1]\n",
            "2024-12-13 00:56:53,581 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.9/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:53,658 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.9/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:53,994 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.9/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:54,116 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.9/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:54,269 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.10/attention/MatMul]\n",
            "2024-12-13 00:56:54,344 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.10/attention/MatMul_1]\n",
            "2024-12-13 00:56:54,345 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.10/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:54,420 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.10/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:54,740 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.10/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:54,869 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.10/final_layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:55,041 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.11/attention/MatMul]\n",
            "2024-12-13 00:56:55,122 INFO     [matmul] Ignore MatMul due to non constant B: /[/hubert/encoder/layers.11/attention/MatMul_1]\n",
            "2024-12-13 00:56:55,123 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.11/attention/Reshape_7_output_0\" not specified\n",
            "2024-12-13 00:56:55,242 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.11/layer_norm/Add_1_output_0\" not specified\n",
            "2024-12-13 00:56:55,754 INFO     [onnx_quantizer] Quantization parameters for tensor:\"/hubert/encoder/layers.11/feed_forward/intermediate_act_fn/Mul_1_output_0\" not specified\n",
            "2024-12-13 00:56:57,058 INFO     [OnnxLoader] Done!\n",
            "2024-12-13 00:56:57,806 INFO     [PitchExtractorManager] Loading pitch extractor rmvpe_onnx\n",
            "2024-12-13 00:57:01,197 INFO     [PipelineGenerator] Loading index...\n",
            "2024-12-13 00:57:01,197 WARNING  [PipelineGenerator] Index file not found. Index will not be used.\n",
            "2024-12-13 00:57:01,197 INFO     [Pipeline] GENERATE INFERENCER<voice_changer.RVC.inferencer.RVCInferencerv2.RVCInferencerv2 object at 0x7f0becb2a050>\n",
            "2024-12-13 00:57:01,197 INFO     [Pipeline] GENERATE EMBEDDER<voice_changer.embedder.OnnxContentvec.OnnxContentvec object at 0x7f0becb127d0>\n",
            "2024-12-13 00:57:01,197 INFO     [Pipeline] GENERATE PITCH EXTRACTOR<voice_changer.pitch_extractor.RMVPEOnnxPitchExtractor.RMVPEOnnxPitchExtractor object at 0x7f0c1e9d1ed0>\n",
            "2024-12-13 00:57:01,279 INFO     [RVCr2] Initialized.\n",
            "2024-12-13 00:57:16,909 INFO     [VoiceChangerManager] update configuration gpu: 0\n",
            "2024-12-13 00:57:16,911 INFO     [DeviceManager] Switched to 0: Tesla T4 (CUDA) (cuda:0). FP16 support: True\n",
            "2024-12-13 00:57:17,260 INFO     [VoiceChangerV2] Allocated SOLA buffer size: 4800\n",
            "2024-12-13 00:57:17,261 INFO     [RVCr2] Initializing...\n",
            "2024-12-13 00:57:17,932 INFO     [RVCInferencerv2] Compiling JIT model...\n",
            "2024-12-13 00:57:19,886 INFO     [EmbedderManager] Loading embedder hubert_base\n",
            "2024-12-13 00:57:19,886 INFO     [OnnxLoader] Converting model to FP16...\n",
            "2024-12-13 00:57:29,342 INFO     [OnnxLoader] Done!\n",
            "2024-12-13 00:57:31,165 INFO     [PitchExtractorManager] Loading pitch extractor rmvpe_onnx\n",
            "2024-12-13 00:57:31,166 INFO     [OnnxLoader] Converting model to FP16...\n",
            "2024-12-13 00:57:41,274 WARNING  [symbolic_shape_infer] Unable to determine if n_samples <= ConvTranspose_308_o0__d2, treat as equal\n",
            "2024-12-13 00:57:42,092 INFO     [OnnxLoader] Done!\n",
            "\u001b[0;93m2024-12-13 00:57:43.516326859 [W:onnxruntime:, transformer_memcpy.cc:74 ApplyImpl] 2 Memcpy nodes are added to the graph main_graph for CUDAExecutionProvider. It might have negative impact on performance (including unable to run CUDA graph). Set session_options.log_severity_level=1 to see the detail logs before this message.\u001b[m\n",
            "2024-12-13 00:57:43,654 INFO     [PipelineGenerator] Loading index...\n",
            "2024-12-13 00:57:43,654 WARNING  [PipelineGenerator] Index file not found. Index will not be used.\n",
            "2024-12-13 00:57:43,654 INFO     [Pipeline] GENERATE INFERENCER<voice_changer.RVC.inferencer.RVCInferencerv2.RVCInferencerv2 object at 0x7f0c1ea14fd0>\n",
            "2024-12-13 00:57:43,654 INFO     [Pipeline] GENERATE EMBEDDER<voice_changer.embedder.OnnxContentvec.OnnxContentvec object at 0x7f0becb8dd50>\n",
            "2024-12-13 00:57:43,654 INFO     [Pipeline] GENERATE PITCH EXTRACTOR<voice_changer.pitch_extractor.RMVPEOnnxPitchExtractor.RMVPEOnnxPitchExtractor object at 0x7f0be45310c0>\n",
            "2024-12-13 00:57:43,720 INFO     [RVCr2] Initialized.\n",
            "2024-12-13 00:57:43,726 INFO     [RVCr2] Allocated audio buffer size: 9792\n",
            "2024-12-13 00:57:43,726 INFO     [RVCr2] Allocated convert buffer size: 18080\n",
            "2024-12-13 00:57:43,727 INFO     [RVCr2] Allocated pitchf buffer size: 114\n",
            "2024-12-13 00:58:55,624 INFO     [VoiceChangerManager] update configuration tran: 12\n",
            "2024-12-13 01:01:32,782 INFO     [VoiceChangerManager] update configuration serverReadChunkSize: 338\n",
            "2024-12-13 01:01:32,783 INFO     [RVCr2] Allocated audio buffer size: 16021\n",
            "2024-12-13 01:01:32,783 INFO     [RVCr2] Allocated convert buffer size: 24320\n",
            "2024-12-13 01:01:32,783 INFO     [RVCr2] Allocated pitchf buffer size: 153\n",
            "2024-12-13 01:05:41,527 INFO     [MMVC_Rest_Fileuploader] paramDict\n",
            "2024-12-13 01:05:41,528 INFO     [VoiceChangerManager] FILE: LoadModelParamFile(name='kobov2.pth', kind='rvcModel', dir='')\n",
            "2024-12-13 01:05:41,528 INFO     [VoiceChangerManager] Moving /tmp/tmpes66vydm/upload_dir/kobov2.pth -> model_dir/1/kobov2.pth\n",
            "2024-12-13 01:05:41,528 INFO     [RVCModelSlotGenerator] RVC:: slotInfo.modelFile kobov2.pth\n",
            "2024-12-13 01:05:41,602 INFO     [RVCModelSlotGenerator] Official Model(pyTorch) : v2\n",
            "2024-12-13 01:05:42,097 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=-1, voiceChangerType='RVC', name='kobov2', description='', credit='', termsOfUseUrl='', iconFile='', speakers={0: 'target'}, modelFile='kobov2.safetensors', modelFileOnnx='', indexFile='', defaultTune=0, defaultFormantShift=0, defaultIndexRatio=0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=48000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 01:05:42,106 INFO     [VoiceChangerManager] params, LoadModelParams(voiceChangerType='RVC', slot=1, isSampleMode=False, sampleId=None, files=[LoadModelParamFile(name='kobov2.pth', kind='rvcModel', dir='')], params={})\n",
            "2024-12-13 01:05:54,711 INFO     [VoiceChangerManager] update configuration modelSlotIndex: 1\n",
            "2024-12-13 01:05:54,711 INFO     [VoiceChangerManager] Model slot is changed 0 -> 1\n",
            "2024-12-13 01:05:54,711 INFO     [RVCr2] Initializing...\n",
            "2024-12-13 01:05:55,689 INFO     [RVCInferencerv2] Compiling JIT model...\n",
            "2024-12-13 01:05:57,598 INFO     [EmbedderManager] Reusing embedder.\n",
            "2024-12-13 01:05:57,598 INFO     [PitchExtractorManager] Reusing pitch extractor.\n",
            "2024-12-13 01:05:57,599 INFO     [PipelineGenerator] Loading index...\n",
            "2024-12-13 01:05:57,599 WARNING  [PipelineGenerator] Index file not found. Index will not be used.\n",
            "2024-12-13 01:05:57,599 INFO     [Pipeline] GENERATE INFERENCER<voice_changer.RVC.inferencer.RVCInferencerv2.RVCInferencerv2 object at 0x7f0c1ea14ee0>\n",
            "2024-12-13 01:05:57,599 INFO     [Pipeline] GENERATE EMBEDDER<voice_changer.embedder.OnnxContentvec.OnnxContentvec object at 0x7f0becb8dd50>\n",
            "2024-12-13 01:05:57,599 INFO     [Pipeline] GENERATE PITCH EXTRACTOR<voice_changer.pitch_extractor.RMVPEOnnxPitchExtractor.RMVPEOnnxPitchExtractor object at 0x7f0be45310c0>\n",
            "2024-12-13 01:05:57,600 INFO     [RVCr2] Initialized.\n",
            "2024-12-13 01:06:20,327 INFO     [VoiceChangerManager] update configuration tran: 21\n",
            "2024-12-13 01:06:21,997 INFO     [VoiceChangerManager] update configuration tran: 19\n",
            "2024-12-13 01:06:29,703 INFO     [VoiceChangerManager] update configuration tran: 8\n",
            "2024-12-13 01:06:30,660 INFO     [VoiceChangerManager] update configuration tran: 17\n",
            "2024-12-13 01:06:32,165 INFO     [VoiceChangerManager] update configuration tran: 10\n",
            "2024-12-13 01:06:33,869 INFO     [VoiceChangerManager] update configuration tran: 15\n",
            "2024-12-13 01:06:35,936 INFO     [VoiceChangerManager] update configuration tran: 7\n",
            "2024-12-13 01:06:37,489 INFO     [VoiceChangerManager] update configuration tran: 15\n",
            "2024-12-13 01:06:39,272 INFO     [VoiceChangerManager] update configuration tran: 11\n",
            "2024-12-13 01:06:41,579 INFO     [VoiceChangerManager] update configuration tran: 12\n",
            "2024-12-13 01:08:40,109 INFO     [ModelSlotManager] UPDATE MODEL INFO: defaultTune=12\n",
            "2024-12-13 01:08:40,110 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=1, voiceChangerType='RVC', name='kobov2', description='', credit='', termsOfUseUrl='', iconFile='', speakers={'0': 'target'}, modelFile='kobov2.safetensors', modelFileOnnx='', indexFile='', defaultTune=12, defaultFormantShift=0, defaultIndexRatio=0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=48000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 01:08:40,117 INFO     [ModelSlotManager] UPDATE MODEL INFO: defaultIndexRatio=0.0\n",
            "2024-12-13 01:08:40,117 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=1, voiceChangerType='RVC', name='kobov2', description='', credit='', termsOfUseUrl='', iconFile='', speakers={'0': 'target'}, modelFile='kobov2.safetensors', modelFileOnnx='', indexFile='', defaultTune=12, defaultFormantShift=0, defaultIndexRatio=0.0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=48000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 01:08:40,123 INFO     [ModelSlotManager] UPDATE MODEL INFO: defaultProtect=0.5\n",
            "2024-12-13 01:08:40,123 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=1, voiceChangerType='RVC', name='kobov2', description='', credit='', termsOfUseUrl='', iconFile='', speakers={'0': 'target'}, modelFile='kobov2.safetensors', modelFileOnnx='', indexFile='', defaultTune=12, defaultFormantShift=0, defaultIndexRatio=0.0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=48000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 01:08:40,130 INFO     [ModelSlotManager] UPDATE MODEL INFO: defaultFormantShift=0.0\n",
            "2024-12-13 01:08:40,130 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=1, voiceChangerType='RVC', name='kobov2', description='', credit='', termsOfUseUrl='', iconFile='', speakers={'0': 'target'}, modelFile='kobov2.safetensors', modelFileOnnx='', indexFile='', defaultTune=12, defaultFormantShift=0.0, defaultIndexRatio=0.0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=48000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 01:08:44,906 INFO     [ModelSlotManager] UPDATE MODEL INFO: defaultTune=12\n",
            "2024-12-13 01:08:44,906 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=1, voiceChangerType='RVC', name='kobov2', description='', credit='', termsOfUseUrl='', iconFile='', speakers={'0': 'target'}, modelFile='kobov2.safetensors', modelFileOnnx='', indexFile='', defaultTune=12, defaultFormantShift=0.0, defaultIndexRatio=0.0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=48000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 01:08:44,910 INFO     [ModelSlotManager] UPDATE MODEL INFO: defaultIndexRatio=0.0\n",
            "2024-12-13 01:08:44,911 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=1, voiceChangerType='RVC', name='kobov2', description='', credit='', termsOfUseUrl='', iconFile='', speakers={'0': 'target'}, modelFile='kobov2.safetensors', modelFileOnnx='', indexFile='', defaultTune=12, defaultFormantShift=0.0, defaultIndexRatio=0.0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=48000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 01:08:44,915 INFO     [ModelSlotManager] UPDATE MODEL INFO: defaultProtect=0.5\n",
            "2024-12-13 01:08:44,915 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=1, voiceChangerType='RVC', name='kobov2', description='', credit='', termsOfUseUrl='', iconFile='', speakers={'0': 'target'}, modelFile='kobov2.safetensors', modelFileOnnx='', indexFile='', defaultTune=12, defaultFormantShift=0.0, defaultIndexRatio=0.0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=48000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 01:08:44,919 INFO     [ModelSlotManager] UPDATE MODEL INFO: defaultFormantShift=0.0\n",
            "2024-12-13 01:08:44,919 INFO     [ModelSlot] SlotInfo::: RVCModelSlot(slotIndex=1, voiceChangerType='RVC', name='kobov2', description='', credit='', termsOfUseUrl='', iconFile='', speakers={'0': 'target'}, modelFile='kobov2.safetensors', modelFileOnnx='', indexFile='', defaultTune=12, defaultFormantShift=0.0, defaultIndexRatio=0.0, defaultProtect=0.5, isONNX=False, modelType='pyTorchRVCv2', modelTypeOnnx='onnxRVC', samplingRate=48000, f0=True, embChannels=768, embOutputLayer=12, useFinalProj=False, deprecated=False, embedder='hubert_base', sampleId='', version='v2')\n",
            "2024-12-13 01:08:55,058 INFO     [MMVC_Namespace] Disconnected SID: kzEmF9lyYCf9wok6AAAB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-12-13T01:09:28+0000 lvl=warn msg=\"Stopping forwarder\" name=http-18888-f22a113b-0ea3-4f7f-aaaf-c431e073b71b acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR\u001b[0m:    Traceback (most recent call last):\n",
            "  File \"asyncio/runners.py\", line 44, in run\n",
            "  File \"asyncio/base_events.py\", line 636, in run_until_complete\n",
            "  File \"asyncio/base_events.py\", line 603, in run_forever\n",
            "  File \"asyncio/base_events.py\", line 1909, in _run_once\n",
            "  File \"asyncio/events.py\", line 80, in _run\n",
            "  File \"main.py\", line 140, in main\n",
            "  File \"main.py\", line 81, in runServer\n",
            "  File \"uvicorn/server.py\", line 68, in serve\n",
            "  File \"contextlib.py\", line 142, in __exit__\n",
            "  File \"uvicorn/server.py\", line 332, in capture_signals\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"starlette/routing.py\", line 700, in lifespan\n",
            "  File \"uvicorn/lifespan/on.py\", line 137, in receive\n",
            "  File \"asyncio/queues.py\", line 159, in get\n",
            "asyncio.exceptions.CancelledError\n",
            "\n",
            "\u001b[32m\u001b[1m\u001b[3mServer Telah Berhenti / Server Was Stopped\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "#=======================Updated=========================\n",
        "\n",
        "# @title **Cell[2]** Start Server **using ngrok**\n",
        "# @markdown This cell will start the server, the first time that you run it will download the models, so it can take a while (~1-2 minutes)\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown You'll need a ngrok account, but <font color=green>**it's free**</font> and easy to create!\n",
        "# @markdown ---\n",
        "# @markdown **1** - Create a <font color=green>**free**</font> account at [ngrok](https://dashboard.ngrok.com/signup) or **login with Google/Github account**\\\n",
        "# @markdown **2** - If you didn't logged in with Google/Github, you will need to **verify your e-mail**!\\\n",
        "# @markdown **3** - Click [this link](https://dashboard.ngrok.com/get-started/your-authtoken) to get your auth token, and place it here:\n",
        "Token = '2gPKwZyv68cWfRNex7aDDPFgCS7_3j4cuDS5sc4tNFXT946vF' # @param {type:\"string\"}\n",
        "# @markdown **4** - *(optional)* Change to a region near to you or keep at United States if increase latency\\\n",
        "# @markdown `Default Region: ap - Asia/Pacific (Singapore)`\n",
        "Region = \"ap - Asia/Pacific (Singapore)\" # @param [\"ap - Asia/Pacific (Singapore)\", \"au - Australia (Sydney)\",\"eu - Europe (Frankfurt)\", \"in - India (Mumbai)\",\"jp - Japan (Tokyo)\",\"sa - South America (Sao Paulo)\", \"us - United States (Ohio)\"]\n",
        "\n",
        "#@markdown **5** - *(optional)* Other options:\n",
        "ClearConsole = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# ---------------------------------\n",
        "# DO NOT TOUCH ANYTHING DOWN BELOW!\n",
        "# ---------------------------------\n",
        "if version == \"V1(new)\":\n",
        "    %cd /content/MMVCServerSIO\n",
        "    if not globals().get('Ready', False):\n",
        "        print(\"Go back and run first cells.\")\n",
        "    else:\n",
        "        from pyngrok import conf, ngrok\n",
        "        MyConfig = conf.PyngrokConfig()\n",
        "        MyConfig.auth_token = Token\n",
        "        MyConfig.region = Region[0:2]\n",
        "        conf.get_default().authtoken = Token\n",
        "        conf.get_default().region = Region\n",
        "        conf.set_default(MyConfig)\n",
        "\n",
        "        import threading, time, socket\n",
        "        PORT = 18888\n",
        "\n",
        "        import json\n",
        "        from pyngrok import ngrok\n",
        "        from IPython.display import clear_output\n",
        "\n",
        "        ngrokConnection = ngrok.connect(PORT)\n",
        "        public_url = ngrokConnection.public_url\n",
        "        set_key('.env', \"ALLOWED_ORIGINS\", json.dumps([public_url]))\n",
        "\n",
        "        def wait_for_server():\n",
        "            while True:\n",
        "                time.sleep(0.5)\n",
        "                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "                result = sock.connect_ex(('127.0.0.1', PORT))\n",
        "                if result == 0:\n",
        "                    break\n",
        "                sock.close()\n",
        "            if ClearConsole:\n",
        "                clear_output()\n",
        "            print(\"--------- SERVER READY! ---------\")\n",
        "            print(\"Your server is available at:\")\n",
        "            print(public_url)\n",
        "            print(\"---------------------------------\")\n",
        "\n",
        "        threading.Thread(target=wait_for_server, daemon=True).start()\n",
        "\n",
        "        !./$path\n",
        "\n",
        "        ngrok.disconnect(ngrokConnection.public_url)\n",
        "        print('\\033[32m\\033[1m\\033[3mServer Telah Berhenti / Server Was Stopped\\033[0m')\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "elif version == \"V1(old)\":\n",
        "\n",
        "    from pyngrok import conf, ngrok\n",
        "    MyConfig = conf.PyngrokConfig()\n",
        "    MyConfig.auth_token = Token\n",
        "    MyConfig.region = Region[0:2]\n",
        "    #conf.get_default().authtoken = Token\n",
        "    #conf.get_default().region = Region\n",
        "    conf.set_default(MyConfig)\n",
        "\n",
        "    import subprocess, threading, time, socket, urllib.request\n",
        "    PORT = 9999\n",
        "\n",
        "    from pyngrok import ngrok\n",
        "    ngrokConnection = ngrok.connect(PORT)\n",
        "    public_url = ngrokConnection.public_url\n",
        "\n",
        "    from IPython.display import clear_output\n",
        "\n",
        "    def wait_for_server():\n",
        "        while True:\n",
        "            time.sleep(0.5)\n",
        "            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "            result = sock.connect_ex(('127.0.0.1', PORT))\n",
        "            if result == 0:\n",
        "                break\n",
        "            sock.close()\n",
        "        if ClearConsole:\n",
        "            clear_output()\n",
        "        print(\"--------- SERVER READY! ---------\")\n",
        "        print(\"Your server is available at:\")\n",
        "        print(public_url)\n",
        "        print(\"---------------------------------\")\n",
        "\n",
        "    threading.Thread(target=wait_for_server, daemon=True).start()\n",
        "\n",
        "    !python3 pengubahsuara.py \\\n",
        "      -p {PORT} \\\n",
        "      --https False \\\n",
        "      --content_vec_500 pretrain/checkpoint_best_legacy_500.pt \\\n",
        "      --content_vec_500_onnx pretrain/content_vec_500.onnx \\\n",
        "      --content_vec_500_onnx_on false \\\n",
        "      --hubert_base pretrain/hubert_base.pt \\\n",
        "      --hubert_base_jp pretrain/rinna_hubert_base_jp.pt \\\n",
        "      --hubert_soft pretrain/hubert/hubert-soft-0d54a1f4.pt \\\n",
        "      --nsf_hifigan pretrain/nsf_hifigan/model \\\n",
        "      --crepe_onnx_full pretrain/crepe_onnx_full.onnx \\\n",
        "      --crepe_onnx_tiny pretrain/crepe_onnx_tiny.onnx \\\n",
        "      --rmvpe pretrain/rmvpe.pt \\\n",
        "      --model_dir model_dir \\\n",
        "      --samples samples.json\n",
        "\n",
        "    ngrok.disconnect(ngrokConnection.public_url)\n",
        "    print('\\033[32m\\033[1m\\033[3mServer Telah Berhenti / Server Was Stopped\\033[0m')\n",
        "\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
        "\n",
        "elif version == \"V2\":\n",
        "\n",
        "    import time\n",
        "    from pyngrok import ngrok\n",
        "    from IPython.display import clear_output, display, Javascript, Audio\n",
        "\n",
        "    Close_Ngrok=True\n",
        "    Open_New_Tab=True\n",
        "    PORT = 8003\n",
        "    LOG_FILE = f\"/content/LOG_FILE_{PORT}\"\n",
        "\n",
        "    def play_notification_sound(url):\n",
        "        display(Audio(url=url, autoplay=True))\n",
        "    Close_Ngrok = True\n",
        "    Open_New_Tab = True\n",
        "\n",
        "    # Start\n",
        "    if mode == \"elf\":\n",
        "        get_ipython().system_raw(f'LD_LIBRARY_PATH=/usr/lib64-nvidia:/usr/lib/x86_64-linux-gnu ./vcclient_latest_for_colab cui --port {PORT} --no_cui true >{LOG_FILE} 2>&1 &')\n",
        "    elif mode == \"zip\":\n",
        "        !LD_LIBRARY_PATH=/usr/lib64-nvidia:/usr/lib/x86_64-linux-gnu ./main cui --port {PORT} --no_cui true &\n",
        "\n",
        "    if Close_Ngrok:\n",
        "        ngrok.kill()\n",
        "\n",
        "    ngrok.set_auth_token(Token)\n",
        "\n",
        "    # Tunggu sampai server dimulai\n",
        "    print('\\033[31m\\033[1m\\033[3mTunggu sampai server dimulai\\033[0m')\n",
        "    time.sleep(130)\n",
        "\n",
        "    main_tunnel = ngrok.connect(PORT)\n",
        "    clear_output()\n",
        "\n",
        "    if Open_New_Tab:\n",
        "        display(Javascript(f'window.open(\"{main_tunnel.public_url}\", \"_blank\");'))\n",
        "\n",
        "    print(\"--------- SERVER LINK ---------\")\n",
        "    print('\\033[32m\\033[1m\\033[3mServer Sudah Berjalan\\033[0m')\n",
        "    print(\"PUBLIC URL:\", main_tunnel.public_url)\n",
        "    print(\"---------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import requests\n",
        "import codecs\n",
        "\n",
        "if version == \"V1(old)\":\n",
        "\n",
        "    #@title **[Optional Cell For V1 Old Okada Voice Changer]** Upload a voice model (Run this before running the Voice Changer)\n",
        "    #@markdown Find your model here [voice-models](https://voice-models.com/)\n",
        "    # @markdown ---\n",
        "    model_slot = \"0\" #@param ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199']\n",
        "\n",
        "    !rm -rf model_dir/$model_slot\n",
        "    #@markdown **[Optional]** Add an icon to the model (Kosongin aja gapapa / It's okay to leave it blank)\n",
        "    icon_link = \"\"  #@param {type:\"string\"}\n",
        "    icon_link = '\"'+icon_link+'\"'\n",
        "    !mkdir model_dir\n",
        "    !mkdir model_dir/$model_slot\n",
        "    #@markdown Put your model's download link here `(must be a zip file and don't use GPT-SoVITS Model)` only supports **huggingface.co** & **google drive**<br>\n",
        "    model_link = \"https://huggingface.co/megaaziib/my-rvc-models-collection/resolve/main/kobo.zip\"  #@param {type:\"string\"}\n",
        "\n",
        "    if model_link.startswith(\"https://www.weights.gg\") or model_link.startswith(\"https://weights.gg\"):\n",
        "        print(\"Links from weights.gg is no longer supported.\")\n",
        "        sys.exit()\n",
        "    elif model_link.startswith(\"https://drive.google.com\"):\n",
        "        model_link = '\"'+model_link+'\"'\n",
        "        !gdown $model_link --fuzzy -O model.zip\n",
        "        print(\"Model from Drive\")\n",
        "    elif model_link.startswith(\"https://huggingface.co\"):\n",
        "        model_link = model_link\n",
        "        model_link = '\"'+model_link+'\"'\n",
        "        !curl -L $model_link > model.zip\n",
        "        print(\"Model from huggingface Link\")\n",
        "    else:\n",
        "        model_link = model_link\n",
        "        model_link = '\"'+model_link+'\"'\n",
        "        !curl -L -O $model_link\n",
        "        !mv ./*.pth model_dir/$model_slot/\n",
        "        print('Model(.pth) or a direct model link.')\n",
        "\n",
        "    # Conditionally set the iconFile based on whether icon_link is empty\n",
        "    if icon_link == '\"\"':\n",
        "        iconFile = \"\"\n",
        "        print(\"icon_link is empty, so no icon file will be downloaded.\")\n",
        "    else:\n",
        "        iconFile = \"icon.png\"\n",
        "        !curl -L $icon_link > model_dir/$model_slot/icon.png\n",
        "\n",
        "    !unzip model.zip -d model_dir/$model_slot\n",
        "\n",
        "    !mv model_dir/$model_slot/*/* model_dir/$model_slot/\n",
        "    !rm -rf model_dir/$model_slot/*/\n",
        "    !rm -rf model.zip\n",
        "    #@markdown **Model Voice Conversion Setting**\n",
        "    Tune = 0  #@param {type:\"slider\",min:-24,max:24,step:1}\n",
        "    Index = 0  #@param {type:\"slider\",min:0,max:1,step:0.1}\n",
        "\n",
        "    param_link = \"\"\n",
        "    if param_link == \"\":\n",
        "        paramset = requests.get(\"https://pastebin.com/raw/P6ar4baa\").text\n",
        "        exec(paramset)\n",
        "\n",
        "    clear_output()\n",
        "    print(\"\\033[93mModel with the name of \"+model_name+\" has been Imported to slot \"+model_slot)\n",
        "\n",
        "elif version == \"V1(new)\":\n",
        "    print('\\033[31m\\033[1m\\033[3mV1 New Belum Support / V1 New is not supported\\033[0m')\n",
        "elif version == \"V2\":\n",
        "    print('\\033[31m\\033[1m\\033[3mV2 Belum Support / V2 is not supported\\033[0m')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N2c7UpbA3eYr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}